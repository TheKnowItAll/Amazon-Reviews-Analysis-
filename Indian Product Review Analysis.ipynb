{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9d28a6",
   "metadata": {},
   "source": [
    "# Installing Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe315a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273be8c6",
   "metadata": {},
   "source": [
    "# Downloading corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceffdded",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a8cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "from spacy import displacy\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.svm import LinearSVC\n",
    "from textblob import TextBlob\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b43355",
   "metadata": {},
   "source": [
    "# Loading Data from CSV to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca41dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this hair oil after viewing so many g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>5</td>\n",
       "      <td>Used This Mama Earth Newly Launched Onion Oil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-10-19</td>\n",
       "      <td>1</td>\n",
       "      <td>So bad product...My hair falling increase too ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Product just smells similar to navarathna hair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>5</td>\n",
       "      <td>I have been trying different onion oil for my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                     name        date  rating  \\\n",
       "0  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-09-06       1   \n",
       "1  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-08-14       5   \n",
       "2  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-10-19       1   \n",
       "3  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-09-16       1   \n",
       "4  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-08-18       5   \n",
       "\n",
       "                                              review  \n",
       "0  I bought this hair oil after viewing so many g...  \n",
       "1  Used This Mama Earth Newly Launched Onion Oil ...  \n",
       "2  So bad product...My hair falling increase too ...  \n",
       "3  Product just smells similar to navarathna hair...  \n",
       "4  I have been trying different onion oil for my ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('C:/Users/SANA JALGAONKAR/Desktop/Text Analysis/Amazon indian product reviews.csv', encoding=\"UTF-8\")\n",
    "reviews_df.head()#path of the csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6835c8",
   "metadata": {},
   "source": [
    "# check the dimensionality of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d0ae52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2782, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e074772",
   "metadata": {},
   "source": [
    "# Checking the null Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8553273e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin      0\n",
       "name      0\n",
       "date      0\n",
       "rating    0\n",
       "review    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any null columns\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b969cb",
   "metadata": {},
   "source": [
    "#### In the the review column, four rows without review text, we drop the rows with the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21300811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin      0\n",
       "name      0\n",
       "date      0\n",
       "rating    0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = reviews_df.dropna()\n",
    "#resetting the index\n",
    "reviews_df = reviews_df.reset_index(drop=True)\n",
    "# any null columns\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57405187",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c981b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am writing this review after using it around 20 days It seems very natural and chemical free and is very gentle on skin But it does its job of cleaning the skin properly It contains tea tree which is one of my favourite ingredients for skin care Give it a try its definitely better than all other chemicals containing face washes And its even affordable as compared to other natural brands available in market '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all characters not number or characters\n",
    "def cleanText(input_string):\n",
    "    modified_string = re.sub('[^A-Za-z0-9]+', ' ', input_string)\n",
    "    return(modified_string)\n",
    "reviews_df['review'] = reviews_df.review.apply(cleanText)\n",
    "reviews_df['review'][150]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a49be",
   "metadata": {},
   "source": [
    "# Extracting the brand name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed7d2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>brandName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this hair oil after viewing so many g...</td>\n",
       "      <td>Mamaearth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>5</td>\n",
       "      <td>Used This Mama Earth Newly Launched Onion Oil ...</td>\n",
       "      <td>Mamaearth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-10-19</td>\n",
       "      <td>1</td>\n",
       "      <td>So bad product My hair falling increase too mu...</td>\n",
       "      <td>Mamaearth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Product just smells similar to navarathna hair...</td>\n",
       "      <td>Mamaearth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>5</td>\n",
       "      <td>I have been trying different onion oil for my ...</td>\n",
       "      <td>Mamaearth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                     name        date  rating  \\\n",
       "0  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-09-06       1   \n",
       "1  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-08-14       5   \n",
       "2  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-10-19       1   \n",
       "3  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-09-16       1   \n",
       "4  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-08-18       5   \n",
       "\n",
       "                                              review  brandName  \n",
       "0  I bought this hair oil after viewing so many g...  Mamaearth  \n",
       "1  Used This Mama Earth Newly Launched Onion Oil ...  Mamaearth  \n",
       "2  So bad product My hair falling increase too mu...  Mamaearth  \n",
       "3  Product just smells similar to navarathna hair...  Mamaearth  \n",
       "4  I have been trying different onion oil for my ...  Mamaearth  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the name we extract the brand\n",
    "reviews_df['brandName'] = reviews_df['name'].str.split('-').str[0]\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a69820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mamaearth      200\n",
       "Godrej         200\n",
       "Titan          200\n",
       "Himalaya       200\n",
       "Cinthol        200\n",
       "Streax         188\n",
       "Society        182\n",
       "Tata           180\n",
       "Dettol         180\n",
       "Amul           164\n",
       "Fastrack       160\n",
       "Mysore         154\n",
       "Patanjali      152\n",
       "Britannia      120\n",
       "Paper           40\n",
       "MYSORE          40\n",
       "Reflex          40\n",
       "Natural         40\n",
       "Maaza           20\n",
       "Glucon          20\n",
       "Coca            20\n",
       "Savlon          20\n",
       "Maggi           20\n",
       "PATANJALI       20\n",
       "NutriChoice     12\n",
       "Indiana          6\n",
       "Name: brandName, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['brandName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef40229e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mamaearth', 'Godrej', 'Titan', 'Maaza', 'Paper', 'Indiana',\n",
       "       'Coca', 'Natural', 'Maggi', 'Glucon', 'Amul', 'Patanjali',\n",
       "       'Dettol', 'Savlon', 'Cinthol', 'Britannia', 'Nutrichoice',\n",
       "       'Streax', 'Himalaya', 'Society', 'Tata', 'Fastrack', 'Reflex',\n",
       "       'Mysore'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['brandName'] = reviews_df['brandName'].str.title()\n",
    "reviews_df.brandName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e9c8a",
   "metadata": {},
   "source": [
    "# Extracting the Product name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20043b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Onion-Growth-Control-Redensyl',\n",
       "       'Percent-Natural-Berry-Toothpaste',\n",
       "       'Natural-Turmeric-Saffron-brightning',\n",
       "       'Illuminate-Vitamin-Radiant-Turmeric',\n",
       "       'Blemishes-Pigmentation-Blemish-Mulberry', 'Face-Wash-100-ml',\n",
       "       'Moisturizing-Baby-Bathing-Oatmeal',\n",
       "       'Protekt-Master-Blaster-Handwash', 'No-1-Bathing-Soap-Lime',\n",
       "       'No-1-Bathing-Soap-Turmeric', 'Direct-Cool-Refrigerator-1905-PTDI',\n",
       "       'aer-Pocket-Bathroom-Fragrance',\n",
       "       'Security-Solutions-SEEC9060-Electronic',\n",
       "       'Matic-Spray-Violet-Valley',\n",
       "       'Security-Solutions-Goldilocks-Personal',\n",
       "       'ViroShield-Disinfecting-VIROSHIELD-30UV',\n",
       "       'Analog-Black-Dial-Watch-1805NM01',\n",
       "       'Analog-White-Dial-Watch-NK1639SL03',\n",
       "       'Karishma-Analog-Blue-Watch-1774SM01',\n",
       "       'Karishma-Analog-Black-Watch-NK1639SM02',\n",
       "       'Octane-Analog-Silver-Watch-NK1650BM03',\n",
       "       'Analog-Black-Dial-Watch-NK1730SL02',\n",
       "       'Karishma-Analog-Champagne-Watch-NK1580YL05',\n",
       "       'Analog-Gold-Dial-Watch-NK1650YM04',\n",
       "       'Karishma-Analog-Black-NK1578SM04', '1-2L',\n",
       "       'Boat-Aamras-Juice-250ml', 'Frutti-Cherries-Frooti-Multicolor',\n",
       "       'Cola-300ml-Pack-6', 'Mango-Juice-1L-Pack', 'Boat-Mixed-Fruit',\n",
       "       'Masala-Noodles-Singles-840g', 'D-Glucose-Based-Beverage-Orange',\n",
       "       'Festive-Delight-Assorted-Jelimals',\n",
       "       'Butter-Pasteurised-100g-Pack', 'Cow-Ghee-500ml',\n",
       "       'Fresh-Paneer-200g', 'Cacao-Chocolate-125g-Pack',\n",
       "       'Cheese-Slices-200g-Pack', 'Fresh-Cream-250ml',\n",
       "       'Pure-Ghee-Pouch-1L', 'Pro-500g-Pouch-Pack',\n",
       "       'Gold-Milk-Homogenised-Standardised', 'Cows-Ghee-1L',\n",
       "       'Aloe-Pimples-Moisturizing-150ml',\n",
       "       'Shatavar-Mushli-Ashwagandha-Churna',\n",
       "       'Kanti-Natural-Cleanser-Shampoo', 'Ayurved-Ltd-CORO-NIL-Tablet',\n",
       "       'UHT-Milk-1000-ml', 'Cows-Ghee-500ml', 'Saundarya-Aloe-Vera-150ml',\n",
       "       'Disinfectant-Multi-Use-Hygiene-Liquid',\n",
       "       'Disinfectant-Cleaner-Home-Fresh', 'Liquid-Refill-Original-1500',\n",
       "       'Multi-Purpose-Disinfectant-Surfaces-Original',\n",
       "       'After-Shave-Lotion-1000', 'Original-Protection-Bathing-125gm',\n",
       "       'Detergent-Liquid-Laundry-Sanitizer-Spring-Blossom',\n",
       "       'Disinfectant-Liquid-Menthol-Cool', 'Lime-Soap-100-Pack',\n",
       "       'Original-Soap-100-Pack', 'Lime-Soap-100g-Pack',\n",
       "       'Original-Soap-100g-Pack', 'Soap-125g-Pack-Free',\n",
       "       'Cool-Soap-100-Pack', 'Confidence-Soap-100g-Pack',\n",
       "       'Cool-Soap-100g-Free', 'NutriChoice-Digestive-100g',\n",
       "       'Good-Day-Cashew-200g', 'Marie-Gold-200g',\n",
       "       'Digestives-grain-Pack-200g', 'Vita-Marie-Gold-150g',\n",
       "       '50-50-Biscuits-Pouch-80g', 'Nice-Time-150g',\n",
       "       'Hair-Serum-Gloss-100ml', 'Shampoo-Enriched-Extracts-Long-Lasting',\n",
       "       'Vitalized-Hair-Serum-300',\n",
       "       'Ultralights-Highlighting-Kit-Collection',\n",
       "       'Shampoo-Colour-Natural-Black-25-ml-Pack',\n",
       "       'Professional-Hold-Funkey-Colour',\n",
       "       'Soft-Hair-Colour-Natural-Black-170', 'Perfumed-Body-Peach-100ml',\n",
       "       '4004G-Baby-Powder-400g', 'Moisturizing-Aloe-Vera-200ml',\n",
       "       'Baby-Shampoo-400-ml', '4003F-Baby-Lotion-400ml', 'Gift-Pack',\n",
       "       'Herbals-Baby-Lotion-400ml', 'Herbals-Anti-Wrinkle-Cream',\n",
       "       'Tea-Regular-250g-Pouch', 'Tea-Regular-Pouch-1kg',\n",
       "       'Tea-Masala-Jar-250g', 'Tea-Minute-Masala-500g',\n",
       "       'Daily-Elachi-Premix-Pouch', 'Tea-Premium-Packet-1000g',\n",
       "       'Tea-Daily-Masala-Premix', 'Tea-Minute-Ginger-Lemongrass',\n",
       "       'Minute-Tea-Masala-500g', 'Tea-Gold-500g', 'Tea-Premium-North-1kg',\n",
       "       'Tea-Gold-1kg', 'Tea-Gold-Leaf-Pouch', 'Tea-Premium-1-5kg',\n",
       "       'Premium-Leaf-South-500g', 'Agni-Leaf-Tea-1kg',\n",
       "       'Casual-Analog-White-Watch-NK3121SM01',\n",
       "       'Analog-Womens-6150SM04-NK6150SM04',\n",
       "       'Casual-Analog-Blue-Watch-NK3124SL02',\n",
       "       'Activity-Tracker-Monitor-SWD90066PP01',\n",
       "       'Economy-2013-Analog-Watch-NK3099SP05',\n",
       "       'Casual-Analog-Grey-Watch-NK3121SL02',\n",
       "       'Casual-Analog-White-Watch-NK3120SL01',\n",
       "       'Analog-Silver-Dial-Watch-NK9332PP06',\n",
       "       'Activity-Tracker-Monitor-SWD90066PP02',\n",
       "       'SANDAL-Mysore-Sandal-Talcum', 'Sandal-Bathing-Soap-125g',\n",
       "       'Sandal-Gold-Soap-Pack', 'Whitening-Rejuvenating-Face-Pack',\n",
       "       'Sandal-Jasmine-Rose-Soap', 'Sandal-Millennium-Soap-150g',\n",
       "       'Sandal-Agarbathies-Pack-Box', 'Sandal-Soaps-Pack-Bars'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the product from the name column\n",
    "products = []\n",
    "for value in reviews_df['name']:\n",
    "    indx = len(value.split('-')[0])+1\n",
    "    products.append(value[indx:])\n",
    "reviews_df['product'] = products\n",
    "reviews_df['product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b87518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>brandName</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this hair oil after viewing so many g...</td>\n",
       "      <td>Mamaearth</td>\n",
       "      <td>Onion-Growth-Control-Redensyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>5</td>\n",
       "      <td>Used This Mama Earth Newly Launched Onion Oil ...</td>\n",
       "      <td>Mamaearth</td>\n",
       "      <td>Onion-Growth-Control-Redensyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-10-19</td>\n",
       "      <td>1</td>\n",
       "      <td>So bad product My hair falling increase too mu...</td>\n",
       "      <td>Mamaearth</td>\n",
       "      <td>Onion-Growth-Control-Redensyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Product just smells similar to navarathna hair...</td>\n",
       "      <td>Mamaearth</td>\n",
       "      <td>Onion-Growth-Control-Redensyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B07W7CTLD1</td>\n",
       "      <td>Mamaearth-Onion-Growth-Control-Redensyl</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>5</td>\n",
       "      <td>I have been trying different onion oil for my ...</td>\n",
       "      <td>Mamaearth</td>\n",
       "      <td>Onion-Growth-Control-Redensyl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                     name        date  rating  \\\n",
       "0  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-09-06       1   \n",
       "1  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-08-14       5   \n",
       "2  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-10-19       1   \n",
       "3  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-09-16       1   \n",
       "4  B07W7CTLD1  Mamaearth-Onion-Growth-Control-Redensyl  2019-08-18       5   \n",
       "\n",
       "                                              review  brandName  \\\n",
       "0  I bought this hair oil after viewing so many g...  Mamaearth   \n",
       "1  Used This Mama Earth Newly Launched Onion Oil ...  Mamaearth   \n",
       "2  So bad product My hair falling increase too mu...  Mamaearth   \n",
       "3  Product just smells similar to navarathna hair...  Mamaearth   \n",
       "4  I have been trying different onion oil for my ...  Mamaearth   \n",
       "\n",
       "                         product  \n",
       "0  Onion-Growth-Control-Redensyl  \n",
       "1  Onion-Growth-Control-Redensyl  \n",
       "2  Onion-Growth-Control-Redensyl  \n",
       "3  Onion-Growth-Control-Redensyl  \n",
       "4  Onion-Growth-Control-Redensyl  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18a8d2",
   "metadata": {},
   "source": [
    "# Reviewing counts and brands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411aed4",
   "metadata": {},
   "source": [
    "#### Installing Chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chart-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d57b9b",
   "metadata": {},
   "source": [
    "#### Installing Cufflinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e70698",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cufflinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "pd.options.display.max_columns = 30\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "reviews_df.groupby(['brandName']).count()['review'].iplot(kind='bar',yTitle='Count',linecolor='black',opacity=0.8,\n",
    "                                                         title=\"Brands\",xTitle=\"Brands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1a161",
   "metadata": {},
   "source": [
    "# Text analysis with NLTK and Vader Sentiment analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246a03e",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6c191",
   "metadata": {},
   "source": [
    "#### converting Review data into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ddae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to lower case\n",
    "reviews_df['clean_review_text']=reviews_df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5d2fc",
   "metadata": {},
   "source": [
    "#### Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations\n",
    "reviews_df['clean_review_text']=reviews_df['clean_review_text'].str.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced498f6",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords=stopwords.words('english')+['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from']\n",
    "def removeStopWords(stopWords, rvw_txt):\n",
    "    newtxt = ' '.join([word for word in rvw_txt.split() if word not in stopWords])\n",
    "    return newtxt\n",
    "reviews_df['clean_review_text'] = [removeStopWords(stopWords,x) for x in reviews_df['clean_review_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408c6e5",
   "metadata": {},
   "source": [
    "#### Splitting text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting text into words\n",
    "tokenList=[]\n",
    "for indx in range(len(reviews_df)):\n",
    "       token=word_tokenize(reviews_df['clean_review_text'][indx])\n",
    "       tokenList.append(token)\n",
    "reviews_df['review_tokens'] = tokenList\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66d1c1",
   "metadata": {},
   "source": [
    "#### Downloading the vader_lexicon Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87abb5bc",
   "metadata": {},
   "source": [
    "#### Initializing the sentiment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4716ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = SentimentIntensityAnalyzer()\n",
    "sentiment_scores=[]\n",
    "sentiment_score_flag = []\n",
    "for text in reviews_df['clean_review_text']:\n",
    "        sentimentResults = sentiment_model.polarity_scores(text)\n",
    "        sentiment_score = sentimentResults[\"compound\"]\n",
    "        #print(sentimentResults)\n",
    "        #The compound value reflects the overall sentiment ranging from -1 being very negative and +1 being very positive.\n",
    "        sentiment_scores.append(sentiment_score)\n",
    "        # marking the sentiments as positive, negative and neutral \n",
    "        if sentimentResults['compound'] >= 0.05 : \n",
    "            sentiment_score_flag.append('positive')\n",
    "  \n",
    "        elif sentimentResults['compound'] <= - 0.05 : \n",
    "            sentiment_score_flag.append('negative')\n",
    "  \n",
    "        else : \n",
    "            sentiment_score_flag.append('neutral')\n",
    "            \n",
    "reviews_df['scores']=sentiment_scores\n",
    "reviews_df['scoreStatus'] = sentiment_score_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67de01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e20778",
   "metadata": {},
   "source": [
    "### Wordcloud displaying top words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fdff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 200,\n",
    "        max_font_size = 40, \n",
    "        scale = 3,\n",
    "        random_state = 42\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize = (20, 20))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "    \n",
    "# print wordcloud\n",
    "show_wordcloud(reviews_df[\"clean_review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print wordcloud for positive review\n",
    "positiveReviews_df =reviews_df.loc[reviews_df['scoreStatus'] == \"positive\"]\n",
    "show_wordcloud(positiveReviews_df[\"clean_review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b532af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print wordcloud for negative reviews\n",
    "negativeReviews_df =reviews_df.loc[reviews_df['scoreStatus'] == \"negative\"]\n",
    "show_wordcloud(positiveReviews_df[\"clean_review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ca2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveReviews_df.groupby(['brandName']).count()['scoreStatus'].iplot(kind='bar',yTitle='Count',linecolor='black',opacity=0.8,\n",
    "                                                         title=\"Brands\",xTitle=\"Brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeReviews_df.groupby(['brandName']).count()['scoreStatus'].iplot(kind='bar',yTitle='Count',linecolor='black',opacity=0.8,\n",
    "                                                         title=\"Brands\",xTitle=\"Brands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a7203",
   "metadata": {},
   "source": [
    "#### Checking Indiana Brandname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e241bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(positiveReviews_df.groupby(['brandName']).count()[\"clean_review_text\"])\n",
    "positiveReviews_df.loc[positiveReviews_df['brandName'] == \"Indiana\"][\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(negativeReviews_df.groupby(['brandName']).count()[\"clean_review_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c3518",
   "metadata": {},
   "source": [
    "#### The 6 reviews for “Indiana” brand are as below and we see them as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910434a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.concat([a, b], axis=1)\n",
    "c.columns = ['positiveReviews','negativeReviews']\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5063e5a",
   "metadata": {},
   "source": [
    "## TF and TF-IDF and Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4202eb8",
   "metadata": {},
   "source": [
    "To represent our text numerically we have the Bag of Words model like TF, TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e979d84",
   "metadata": {},
   "source": [
    "TF-IDF aims to quantify the importance of a given word relative to other words in the document and in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491db171",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = CountVectorizer()\n",
    "features.fit(reviews_df[\"clean_review_text\"])\n",
    "print(len(features.vocabulary_))\n",
    "print(features.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31249af3",
   "metadata": {},
   "source": [
    "BoW is a classical text representation technique. The text under consideration as a collection of words while ignoring the order and context. BoW converts text into the matrix of occurrence of words within a given document. It focuses on whether given words occurred or not in the document, and it generates a matrix that we might see referred to as a BoW matrix or a document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37205f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagofWords = features.transform(reviews_df[\"clean_review_text\"])\n",
    "print(bagofWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0183e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bagofWords.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc63d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb2c7f",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8647819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([positiveReviews_df,negativeReviews_df])\n",
    "df = df[[\"clean_review_text\",\"scoreStatus\"]]\n",
    "df['scoreStatus'] = (df['scoreStatus'] == 'positive')*1\n",
    "X = df[\"clean_review_text\"]\n",
    "y = df[\"scoreStatus\"]\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features.fit_transform(X_train)\n",
    "X_test = features.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb23dafe",
   "metadata": {},
   "source": [
    "# Logistic Regression for training the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2875180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold cross validation with k=5\n",
    "scores = cross_val_score(LogisticRegression(),X_train,y_train,cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Model building\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6089d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion Matrix\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ff052",
   "metadata": {},
   "source": [
    "# How the trained model works on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac182602",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"the product great\"\n",
    "model.predict(features.transform([text]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acaf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"bad\"\n",
    "model.predict(features.transform([text]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905959d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"sucks\"\n",
    "model.predict(features.transform([text]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"very bad\"\n",
    "model.predict(features.transform([text]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ca9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"not good\"\n",
    "model.predict(features.transform([text]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d355ea",
   "metadata": {},
   "source": [
    "great and bad rightly predicted but the model wrongly predicts “sucks” and “not good”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06684e2c",
   "metadata": {},
   "source": [
    "# Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_word=word_tokenize((reviews_df['clean_review_text'].to_string()))\n",
    "#Frequency Distribution\n",
    "fdist = FreqDist(tokenized_word)\n",
    "# Frequency Distribution Plot\n",
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()\n",
    "'='"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93a380",
   "metadata": {},
   "source": [
    "# Text Analytics with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = reviews_df['review'][1130]\n",
    "doc=nlp(text)\n",
    "type(doc)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dca0f6",
   "metadata": {},
   "source": [
    "#### Tokenizing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokens\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8095d",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords\n",
    "stopwords=spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopWords = list(stopwords)\n",
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f529fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.is_stop == False:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a534f357",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc346a7c",
   "metadata": {},
   "source": [
    "Finding the roots of all the words using spaCy lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doc))\n",
    "doc2=[]\n",
    "for token in doc:\n",
    "    if not token.is_stop:\n",
    "        doc2.append(token)\n",
    "print(len(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "for review_text in doc:\n",
    "    print(review_text.text,review_text.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88574406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS\n",
    "for token in doc:\n",
    "   print(token,token.tag_,token.pos_,spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc,style='dep',jupyter=True,options={'distance':90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7130e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text,'---->',entity.label_)\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33bde8e",
   "metadata": {},
   "source": [
    "## Downloaded the large pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word vectors and similarity\n",
    "#large pre trained model\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb7346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text,'---->',token.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f93e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text,'',token.vector_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46975186",
   "metadata": {},
   "source": [
    "### Checking the Similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity score\n",
    "text=\"eat\"\n",
    "text1=\"ate\"\n",
    "doc=nlp(text)\n",
    "doc1=nlp(text1)\n",
    "doc.similarity(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa151ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity score\n",
    "text=\"good\"\n",
    "text1=\"bad\"\n",
    "doc=nlp(text)\n",
    "doc1=nlp(text1)\n",
    "doc.similarity(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be49934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity score\n",
    "text=\"hot\"\n",
    "text1=\"summer\"\n",
    "doc=nlp(text)\n",
    "doc1=nlp(text1)\n",
    "doc.similarity(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity score\n",
    "text=\"excellent\"\n",
    "text1=\"good\"\n",
    "doc=nlp(text)\n",
    "doc1=nlp(text1)\n",
    "doc.similarity(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity score\n",
    "text=\"sucks\"\n",
    "text1=\"bad\"\n",
    "doc=nlp(text)\n",
    "doc1=nlp(text1)\n",
    "doc.similarity(doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f0471",
   "metadata": {},
   "source": [
    "### Combining positive and negative datasets to build the training data for training a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([positiveReviews_df,negativeReviews_df])\n",
    "df = df[[\"clean_review_text\",\"scoreStatus\"]]\n",
    "df['scoreStatus'] = (df['scoreStatus'] == 'positive')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "punct = string.punctuation\n",
    "print(punct)\n",
    "def cleanText(sent):\n",
    "    doc = nlp(sent)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma != \"-PRON-\":\n",
    "            tokens.append(token.lemma_.lower().strip())\n",
    "        else:\n",
    "            tokens.append(token.lemma_)\n",
    "            \n",
    "    cleanTokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopWords and token not in punct:\n",
    "            cleanTokens.append(token)\n",
    "    return cleanTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF\n",
    "tfidf = TfidfVectorizer(tokenizer = cleanText)\n",
    "classifier = LinearSVC()\n",
    "X = df[\"clean_review_text\"]\n",
    "y = df[\"scoreStatus\"]\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1cbf0",
   "metadata": {},
   "source": [
    "### Training the model with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e71da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('tfidf',tfidf),('clf',classifier)])\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea598ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea081f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be6f78",
   "metadata": {},
   "source": [
    "### Analyzing with TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ff61f",
   "metadata": {},
   "source": [
    "polarity varies from -1 (negative) to +1 (positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e7bb9",
   "metadata": {},
   "source": [
    "subjectivity varies from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2018a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "blob = TextBlob(str(reviews_df['review']))\n",
    "pos_df = pd.DataFrame(blob.tags, columns = ['word' , 'pos'])\n",
    "pos_df = pos_df.pos.value_counts()[:20]\n",
    "pos_df.iplot(\n",
    "    kind='bar',\n",
    "    xTitle='POS',\n",
    "    yTitle='count', \n",
    "    title='Top 20 Part-of-speech tagging for review corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f31e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "reviews_df[\"polarity\"] = reviews_df[\"review\"].apply(pol)\n",
    "reviews_df[\"subjectivity\"] = reviews_df[\"review\"].apply(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of rating\n",
    "sns.countplot(x='rating', data=reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b55ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97577e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"negative reviews\")\n",
    "most_negative = reviews_df[reviews_df.polarity == -1].review.head()\n",
    "print(most_negative)\n",
    "print(\"positive reviews\")\n",
    "most_positive = reviews_df[reviews_df.polarity == 1].review.head()\n",
    "print(most_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc719e",
   "metadata": {},
   "source": [
    "### Text analysis with gensim and word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315dcb95",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eeebfc",
   "metadata": {},
   "source": [
    "Word2Vec actually takes the semantic meaning of the words and their relationships between other words. It learns all the internal relationships between the words.It represents the word in dense vector form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd61fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = reviews_df['review_tokens'][10:20]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7830c",
   "metadata": {},
   "source": [
    "Using Gensim’s library we have Word2Vec which takes parameters like min_count = 1 considers only if word repeats more than 1 time in entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff89c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab\n",
    "words=list(model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Downloading PUNKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98964f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsText = reviews_df.clean_review_text.values\n",
    "reviewsVec = [nltk.word_tokenize(review) for review in reviewsText]\n",
    "len(reviewsVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb727db",
   "metadata": {},
   "source": [
    "#### Using the trained model to find the similarity of certain word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08875671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(reviewsVec,min_count=1, size=32)\n",
    "model.most_similar('soothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(reviewsVec,min_count=1, size=32)\n",
    "model.most_similar('packaging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a3fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
